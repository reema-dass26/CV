<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Monte Carlo-Based Brick Breaker Game</title>
    <link rel="stylesheet" href="../styles.css">
</head>
<body>
    <header>
        <h1>Monte Carlo-Based Brick Breaker Game</h1>
    </header>
    <main>
        <section class="project-details">
            <div class="image-gallery">
                <!-- Replace with relevant project images -->
                <img src="images/xx.gif" alt="Gameplay Overview" class="project-thumbnail">
            </div>
            <h2>Project Overview</h2>
            <p>The major goals for this project are:</p>
            <ul>
                <li>Implementing a Monte Carlo-based reinforcement learning agent using a greedy epsilon strategy with a threshold of 0.5 to play a brick breaker game.</li>
                <li>Training the agent to maximize its reward by hitting bricks, tracking the ball, and ensuring the paddle bounces the ball effectively while avoiding game loss.</li>
                <li>Simulating the game environment with specific brick layouts, ball, and paddle movements, allowing the agent to learn from actions and observations during the game.</li>
            </ul>
        
            <h2>Technologies Used</h2>
            <ul>
                <li>Python</li>
                <li>Monte Carlo Methods</li>
                <li>Greedy Epsilon Strategy</li>
                <li>Reinforcement Learning</li>
                <li>Pygame (for environment simulation)</li>
            </ul>
        
            <h2>Project Highlights</h2>
            <ul>
                <li>Created an environment to simulate the brick breaker game with a paddle and ball, featuring specific brick layouts.</li>
                <li>Developed an agent that learns optimal gameplay strategies through trial and error, maximizing the reward by tracking the ball and hitting the bricks.</li>
                <li>Incorporated various aspects of the game, such as ball movement, paddle behavior, brick layout, and game state observation (e.g., X axis offset, paddle speed, and ball speed).</li>
            </ul>
        
            <h2>Future Scope</h2>
            <p>Future plans for this project include optimizing the agent's performance, improving the learning algorithm to handle different levels of difficulty, and adding new features like power-ups and enhanced collision effects.</p>
        </section>
        
        <footer>
            <a href="https://github.com/reema-dass26/Exercise3-RL/tree/main" class="btn-primary">Explore My Work</a>
            <a href="../index.html" class="btn-primary">Back to Projects</a>
        </footer>
    </main>
</body>
</html>
